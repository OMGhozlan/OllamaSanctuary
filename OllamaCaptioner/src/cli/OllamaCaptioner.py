import os
import subprocess
import base64
import ollama
import time
import logging
from pathlib import Path
import typer
import pyfiglet
from inquirer import list_input
from yaspin import yaspin
from difflib import get_close_matches

app = typer.Typer()

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

def encode_image_to_base64(filepath):
    """Encode an image to a base64 string.

    Args:
        filepath: Path to the image file.

    Returns:
        Base64-encoded image string.
    """
    try:
        with open(filepath, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        logging.error(f"Error encoding image {filepath}: {e}")
        raise

def query_llava_model(image_base64, prompt, model_name, ollama_client):
    """Query the LLaVa model with an image and prompt.

    Args:
        image_base64: Base64-encoded image string.
        prompt: Text prompt for the model.
        model_name: Name of the model to use.
        ollama_client: Initialized Ollama client.

    Returns:
        Caption generated by the model.
    """
    try:
        response = ollama_client.chat(model=model_name, messages=[
            {'role': 'user', 'content': prompt, 'images': [image_base64]}])
        return response['message']['content']
    except ollama.ResponseError as e:
        logging.error(f"LLaVa model error: {e}")
        return f"Error: {e}"

def validate_model(model_name, ollama_client):
    """Validate if the specified model exists.

    Args:
        model_name: Name of the model to validate.
        ollama_client: Initialized Ollama client.

    Returns:
        None. Raises an error if the model does not exist.
    """
    model_list = ollama_client.list()['models']
    model_names = [model['name'] for model in model_list]

    for model in model_list:
        print(f"Model Name: {model['name']}")

    if model_name not in model_names:
        suggestions = get_close_matches(model_name, model_names, n=3)
        suggestion_message = (f"Model '{model_name}' not found. Did you mean: "
                              f"{', '.join(suggestions)}?" if suggestions else "No similar models found.")
        logging.error(suggestion_message)
        raise RuntimeError(suggestion_message)

def write_caption_to_file(image_path, caption, extension=".txt"):
    """Write the caption to a text file with the same name as the image.

    Args:
        image_path: Path to the image.
        caption: Caption text.
        extension: File extension for the output file (default: .txt).
    """
    try:
        if extension not in [".txt", ".caption", ".cap"]:
            logging.warning(f"Invalid extension {extension}, defaulting to .txt")
            extension = ".txt"
        caption_path = image_path.with_suffix(extension)
        with open(caption_path, 'w') as file:
            file.write(caption)
        logging.info(f"Caption saved to {caption_path}")
    except Exception as e:
        logging.error(f"Error writing caption for {image_path}: {e}")
        raise

def process_directory(directory_path, prompt, model_name, ollama_client, extension=".txt", prepend_text=""):
    """Process all images in a directory and generate captions.

    Args:
        directory_path: Path to the directory containing images.
        prompt: Prompt for the captions.
        model_name: Name of the model to use.
        ollama_client: Initialized Ollama client.
        extension: File extension for the output files (default: .txt).
    """
    image_extensions = ['.png', '.jpg', '.jpeg', '.webp']
    images = [p for p in directory_path.iterdir() if p.suffix.lower() in image_extensions]

    if not images:
        logging.warning("No images found in the directory.")
        return

    total_images = len(images)
    logging.info(f"Found {total_images} images in {directory_path}")

    start_time = time.time()

    with yaspin(text="Processing images", color="cyan") as spinner:
        for idx, image_path in enumerate(images):
            caption_file = image_path.with_suffix(extension)
            if caption_file.exists():
                logging.info(f"Skipped {image_path.name}, caption file already exists.")
                continue

            try:
                spinner.text = f"Processing {image_path.name} ({idx + 1}/{total_images})"
                image_base64 = encode_image_to_base64(image_path)
                caption = query_llava_model(image_base64, prompt, model_name, ollama_client)

                if "Error" in caption:
                    logging.error(caption)
                else:
                    write_caption_to_file(image_path, f'{prepend_text},{caption}', extension)

            except Exception as e:
                logging.error(f"Error processing {image_path.name}: {e}")

            elapsed_time = time.time() - start_time
            avg_time_per_image = elapsed_time / (idx + 1)
            estimated_total_time = avg_time_per_image * total_images
            estimated_time_left = estimated_total_time - elapsed_time

            spinner.text = (f"{100 * (idx + 1) / total_images:.2f}% complete - "
                            f"Elapsed: {elapsed_time:.2f}s, "
                            f"ETA: {estimated_time_left:.2f}s")

def is_ollama_running():
    try:
        # Check if Ollama is running by listing the processes
        result = subprocess.run(['tasklist'], capture_output=True, text=True)
        return 'ollama.exe' in result.stdout
    except Exception as e:
        typer.echo(f"Error checking Ollama status: {e}")
        return False

def start_ollama():
    try:
        subprocess.Popen(['ollama', 'serve'])
        typer.echo("Ollama started successfully.")
    except Exception as e:
        typer.echo(f"Error starting Ollama: {e}")
        raise typer.Exit()

@app.command()
def main(model_name="llava:13b", extension=".txt"):
    """Main entry point for the script."""
    print(pyfiglet.figlet_format("Image Captioner"))

    if not is_ollama_running():
        start_ollama()

    directory = Path(typer.prompt("Enter the directory containing images"))
    if not directory.is_dir():
        typer.echo("Invalid directory. Please try again.")
        raise typer.Exit()

    prompt_files = [f for f in os.listdir('.') if os.path.isfile(f) and f.endswith(('.txt', '.prompt'))]
    if prompt_files:
        prompt_file = Path(list_input("Select the prompt file", choices=prompt_files))
        if not prompt_file.is_file():
            typer.echo("Invalid prompt file. Please try again.")
            raise typer.Exit()
        try:
            with open(prompt_file, 'r') as file:
                prompt = file.read()
        except Exception as e:
            typer.echo(f"Error reading prompt file: {e}")
            raise typer.Exit()
    else:
            system_prompt_path = Path(__file__).parent / "System.prompt"
            if system_prompt_path.is_file():
                try:
                    with open(system_prompt_path, 'r') as file:
                        prompt = file.read()
                except Exception as e:
                    typer.echo(f"Error reading System.prompt file: {e}")
                    raise typer.Exit()
            else:
                prompt = typer.prompt("System.prompt file not found. Enter your prompt directly")


    prepend_text = typer.prompt("Enter text to prepend to the caption")

    ollama_client = ollama.Client()
    validate_model(model_name, ollama_client)
    process_directory(directory, prompt, model_name, ollama_client, extension, prepend_text)

if __name__ == "__main__":
    app()
